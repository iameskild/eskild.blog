<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>LLMs on eskild.blog</title><link>https://www.eskild.blog/tags/llms/</link><description>Recent content in LLMs on eskild.blog</description><generator>Hugo -- 0.142.0</generator><language>en-us</language><lastBuildDate>Sat, 09 Dec 2023 17:00:17 +0700</lastBuildDate><atom:link href="https://www.eskild.blog/tags/llms/index.xml" rel="self" type="application/rss+xml"/><item><title>What's your humor setting Co-Pilot?</title><link>https://www.eskild.blog/posts/2023-12-09-rr/</link><pubDate>Sat, 09 Dec 2023 17:00:17 +0700</pubDate><guid>https://www.eskild.blog/posts/2023-12-09-rr/</guid><description>&lt;img src="https://www.eskild.blog/images/copilot_humor_setting.jpg" alt="Meme from interstellar" width="1000">
&lt;p>As it currently stands, I pay for two AI services,
&lt;a href="https://openai.com/blog/chatgpt-plus" target="_blank">ChatGPT Plus&lt;/a> and
&lt;a href="https://github.com/features/copilot" target="_blank">GitHub's Co-Pilot&lt;/a> but this number will surely increase in the coming months and years. I think the term &amp;ldquo;co-pilot&amp;rdquo; perfectly captures the &lt;em>current&lt;/em> relationship; these are tools that help me automate some of the boring or tedious tasks while also acting as an assistant that I can use to bounce ideas off.&lt;/p>
&lt;p>Recently, while working on a side project, I needed a real URL for some testing. As I began to type out &lt;code>url = &amp;quot;https://&lt;/code>, Co-Pilot generated a suggestion that I could accept by hitting tab. At this point, it didn&amp;rsquo;t matter what the URL was so I accepted the suggestion. Any guesses what the URL was for? What if I told you it was for a YouTube video?&lt;/p></description><content:encoded><![CDATA[<img src="/images/copilot_humor_setting.jpg" alt="Meme from interstellar" width="1000">
<p>As it currently stands, I pay for two AI services,  
<a href="https://openai.com/blog/chatgpt-plus" target="_blank">ChatGPT Plus</a> and  
<a href="https://github.com/features/copilot" target="_blank">GitHub's Co-Pilot</a> but this number will surely increase in the coming months and years. I think the term &ldquo;co-pilot&rdquo; perfectly captures the <em>current</em> relationship; these are tools that help me automate some of the boring or tedious tasks while also acting as an assistant that I can use to bounce ideas off.</p>
<p>Recently, while working on a side project, I needed a real URL for some testing. As I began to type out <code>url = &quot;https://</code>, Co-Pilot generated a suggestion that I could accept by hitting tab. At this point, it didn&rsquo;t matter what the URL was so I accepted the suggestion. Any guesses what the URL was for? What if I told you it was for a YouTube video?</p>
<p>If you guessed, Rick Astley&rsquo;s <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">&ldquo;Never Gonna Give You Up&rdquo; music video</a>, you would be correct. I got  
<a href="https://en.wikipedia.org/wiki/Rickrolling" target="_blank">rickrolled</a> by my Co-Pilot, damn!</p>
<hr>
<p>Without going into too much detail on how these Large Language Models (LLMs) work, it&rsquo;s important to know that these LLMs are trained on billions and billions of lines of text data from online sources including blogs, forums, and digitized books, just to name a few.  What this means is that a large fraction of all the entertaining, beautiful, mean, hopeful, hateful, weird and wonderful things we have collectively written, have been internalized by these LLMs.</p>
<p>It&rsquo;s not a huge surprise that a URL generated by Co-Pilot would be one of the most famous internet memes. I would guess it&rsquo;s among the top 5 common URLs found in the &ldquo;wild&rdquo;.</p>
<p>This experience has once again highlighted that interacting with these LLMs - at least at this point in their development - is like interacting with a mirror of humanity. Training these large models on our collective knowledge has proven that, when concentrated in one entity like GPT4, it has the potential to reflect the vast spectrum of human behavior and culture, both the profound and the trivial.</p>
<p>As AI continues to evolve, the line between tool and collaborator will become increasingly blurred. Today, we might see AI as a &ldquo;co-pilot&rdquo;, but in the future, these systems could become more akin to partners in our creative and professional endeavors. Or perhaps AIs could dispense with the need for a human &ldquo;pilot&rdquo; altogether.</p>
<blockquote>
<p>Most of the previous two paragraphs were completed for my by ChatGPT using the previous paragraphs as the prompt.</p>
</blockquote>
<p>I will conclude by encouraging folks who create content - practically speaking, everyone - to think twice before spreading lies, hate, or any other less-than-flattering ideas that will eventually be picked up by future LLMs; we should strive to ensure the best version of humanity is captured in the future training data sets.</p>
<p>If  
<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" target="_blank">reinforcement learning with human feedback</a> (RLHF) is like scolding a child who swears, then improving the training dataset is akin to not swearing in front of the child to begin with.</p>
<p>Let&rsquo;s not swear in front of the AI.</p>
]]></content:encoded></item></channel></rss>